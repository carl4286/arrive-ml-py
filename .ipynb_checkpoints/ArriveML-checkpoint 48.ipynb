{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ML algorithms\n",
    "    Dimensionality reduction- eliminate reduntant variables, use as pre-processing before training regression algorithm\n",
    "    Random forest regression- use to actulally predict daily volumes\n",
    "    \n",
    "Deep Learning Models\n",
    "    Neural nets- similar application to random forest regression, but more computationally intensive, needs a lot more data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Import pre-generated CSV file with several colums\n",
    "    date (string)\n",
    "    arrive_num (int)\n",
    "    acuity_1 (int)\n",
    "    acuity_2 (int)\n",
    "    acuity_3 (int)\n",
    "    acuity_4 (int)\n",
    "    acuity_5 (int)\n",
    "    AWIND (int, average wind speed)\n",
    "    PRCP (int, inches precipitation)\n",
    "    TMAX (int, max temp)\n",
    "    TMIN (int, min temp)\n",
    "    \n",
    "Include or extrapolate the following\n",
    "    day_of_week (trig thing)\n",
    "    week_of_year (trig thing)\n",
    "    running_7d_avg (int)\n",
    "    holiday_dist (int)\n",
    "\n",
    "Optional future\n",
    "    temp (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  arrive_num  acuity_1  acuity_2  acuity_3  acuity_4  acuity_5  \\\n",
      "0 2022-12-01         303         1        37       150       101        11   \n",
      "1 2022-12-02         286         1        33       156        87         8   \n",
      "2 2022-12-03         280         6        44       137        90         1   \n",
      "3 2022-12-04         245         6        45       117        73         0   \n",
      "4 2022-12-05         278         3        31       139       100         0   \n",
      "5 2022-12-06         304         1        34       161        99         4   \n",
      "6 2022-12-07         225         1        27       123        69         4   \n",
      "7 2022-12-08         280         1        41       154        75         5   \n",
      "8 2022-12-09         275         3        34       148        83         5   \n",
      "9 2022-12-10         226         1        30       120        68         4   \n",
      "\n",
      "  day_of_week  week_of_year  AWND  PRCP  TMAX  TMIN  \n",
      "0       thurs            49  4.47   0.0    56    49  \n",
      "1         fri            49  2.01   0.0    58    47  \n",
      "2         sat            49  2.01   0.0    71    41  \n",
      "3         sun            50  2.01   0.0    66    38  \n",
      "4         mon            50  3.58   0.0    60    46  \n",
      "5        tues            50  2.24   0.0    57    38  \n",
      "6         wed            50  3.13   0.0    58    38  \n",
      "7       thurs            50  1.57   0.0    60    33  \n",
      "8         fri            50  1.12   0.0    60    32  \n",
      "9         sat            50  1.12   0.0    61    32  \n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "import pandas as pd\n",
    "\n",
    "# Import raw data and preview contents\n",
    "raw_arrival_data = pd.read_csv(\"data/ruhs_arrivals_raw_data.csv\", parse_dates=['date'], infer_datetime_format=True)\n",
    "raw_weather_data = pd.read_csv(\"data/moval_weather.csv\", parse_dates=['DATE'], infer_datetime_format=True)\n",
    "\n",
    "# Add weather data, remove redundant date column\n",
    "raw_data = pd.merge(raw_arrival_data, raw_weather_data, left_on=['date'], right_on=['DATE'], how='inner')\n",
    "raw_data = raw_data.drop('DATE', axis = 1)\n",
    "\n",
    "print(raw_data.head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is where to add derived features like running 7 day average volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'week_of_year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'week_of_year'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-59ff9572e0ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Cyclic encoding for week of year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_of_year_sin'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_of_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_of_year_cos'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'week_of_year'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m52\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'week_of_year'"
     ]
    }
   ],
   "source": [
    "#import python-dateutil as dateutil\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# Cyclic encodinf for day of week\n",
    "raw_data['date'] = pd.to_datetime(raw_data.date)\n",
    "raw_data['day_of_week'] = raw_data.date.dt.weekday\n",
    "\n",
    "raw_data['day_of_week_sin'] = np.sin(raw_data['day_of_week'] * (2 * np.pi / 7))\n",
    "raw_data['day_of_week_cos'] = np.cos(raw_data['day_of_week'] * (2 * np.pi / 7))\n",
    "\n",
    "raw_data = raw_data.drop('day_of_week', axis=1)\n",
    "\n",
    "# Cyclic encoding for week of year\n",
    "raw_data['week_of_year_sin'] = np.sin(raw_data['week_of_year'] * (2 * np.pi / 52))\n",
    "raw_data['week_of_year_cos'] = np.cos(raw_data['week_of_year'] * (2 * np.pi / 52))\n",
    "\n",
    "raw_data = raw_data.drop('week_of_year', axis=1)\n",
    "\n",
    "# Calculate running 7-day average\n",
    "arrive_nums = raw_data['arrive_num']\n",
    "running_7d_avg = []\n",
    "for i, arrivals in enumerate(arrive_nums):\n",
    "    prev_index = i-8\n",
    "    start_range = prev_index if prev_index >= 0 else 0\n",
    "    prev_7_days = arrive_nums[start_range : i]\n",
    "    if prev_7_days.empty : prev_7_days = [arrivals]\n",
    "    running_7d_avg.append(np.mean(prev_7_days))\n",
    "raw_data['running_7d_avg'] = running_7d_avg\n",
    "    \n",
    "# TODO: add distance from holiday\n",
    "holidays = np.array(USFederalHolidayCalendar().holidays(start='2022-01-02', end=pd.to_datetime(\"today\")))\n",
    "\n",
    "avail_dates = raw_data['date']\n",
    "is_before_holiday = []\n",
    "is_holiday = []\n",
    "is_after_holiday = []\n",
    "for date in avail_dates:\n",
    "    delta_from_holidays = np.datetime64(date) - holidays\n",
    "    days_from_holiday = [(x / np.timedelta64(1, 'D')) + 1 for x in delta_from_holidays]\n",
    "    smallest_delta = min(days_from_holiday, key=abs)\n",
    "    is_before_holiday.append(np.isclose(smallest_delta, -1.0))\n",
    "    is_holiday.append(np.isclose(smallest_delta, 0.0))\n",
    "    is_after_holiday.append(np.isclose(smallest_delta, 1.0))\n",
    "raw_data['is_before_holiday'] = is_before_holiday\n",
    "raw_data['is_holiday'] = is_holiday\n",
    "raw_data['is_after_holiday'] = is_after_holiday\n",
    "\n",
    "# Normalize temps\n",
    "raw_data['TMAX'] = raw_data['TMAX'] / raw_data['TMAX'].max()\n",
    "\n",
    "print(raw_data.head(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date column, as we only need this to extrapolate other features, not to train model\n",
    "if not raw_data['date'].empty : raw_data = raw_data.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Labels\n",
    "    arrive_num\n",
    "    acuity_1\n",
    "    acuity_2\n",
    "    acuity_3\n",
    "    acuity_4\n",
    "    acuity_5\n",
    "Features\n",
    "    day_of_week\n",
    "    week_of_year\n",
    "    running_7d_avg\n",
    "    holiday_dist\n",
    "    AWND\n",
    "    PRCP\n",
    "    TMAX\n",
    "    TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     303\n",
      "1     286\n",
      "2     280\n",
      "3     245\n",
      "4     278\n",
      "     ... \n",
      "64    270\n",
      "65    233\n",
      "66    247\n",
      "67    292\n",
      "68    296\n",
      "Name: arrive_num, Length: 69, dtype: int64\n",
      "    week_of_year_sin  week_of_year_cos   AWND  PRCP  TMAX  TMIN  \\\n",
      "0          -0.354605          0.935016   4.47   0.0    56    49   \n",
      "1          -0.354605          0.935016   2.01   0.0    58    47   \n",
      "2          -0.354605          0.935016   2.01   0.0    71    41   \n",
      "3          -0.239316          0.970942   2.01   0.0    66    38   \n",
      "4          -0.239316          0.970942   3.58   0.0    60    46   \n",
      "..               ...               ...    ...   ...   ...   ...   \n",
      "64          0.568065          0.822984   2.01   0.0    67    37   \n",
      "65          0.568065          0.822984   2.01   0.0    69    32   \n",
      "66          0.663123          0.748511   3.58   0.0    61    37   \n",
      "67          0.663123          0.748511  12.08   0.0    62    39   \n",
      "68          0.663123          0.748511   3.13   0.0    66    34   \n",
      "\n",
      "    running_7d_avg  is_before_holiday  is_holiday  is_after_holiday  \\\n",
      "0       303.000000              False       False             False   \n",
      "1       303.000000              False       False             False   \n",
      "2       294.500000              False       False             False   \n",
      "3       289.666667              False       False             False   \n",
      "4       278.500000              False       False             False   \n",
      "..             ...                ...         ...               ...   \n",
      "64      266.750000              False       False             False   \n",
      "65      268.000000              False       False             False   \n",
      "66      264.125000              False       False             False   \n",
      "67      266.000000              False       False             False   \n",
      "68      273.500000              False       False             False   \n",
      "\n",
      "    day_of_week_sin  day_of_week_cos  \n",
      "0          0.433884        -0.900969  \n",
      "1         -0.433884        -0.900969  \n",
      "2         -0.974928        -0.222521  \n",
      "3         -0.781831         0.623490  \n",
      "4          0.000000         1.000000  \n",
      "..              ...              ...  \n",
      "64        -0.433884        -0.900969  \n",
      "65        -0.974928        -0.222521  \n",
      "66        -0.781831         0.623490  \n",
      "67         0.000000         1.000000  \n",
      "68         0.781831         0.623490  \n",
      "\n",
      "[69 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define features and labels\n",
    "\n",
    "# Labels: values we want to predict\n",
    "labels = raw_data['arrive_num'] # Un-comment to predict total daily arrivals only\n",
    "#labels = raw_data[['arrive_num', 'acuity_1', 'acuity_2', 'acuity_3', 'acuity_4', 'acuity_5']] # Un-comment to predict arrivals and acuities\n",
    "print(labels)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Features: data that will train model, corresponds to input data when predicting labels\n",
    "features = raw_data[['week_of_year_sin', 'week_of_year_cos', 'AWND', 'PRCP', 'TMAX', 'TMIN', 'running_7d_avg', 'is_before_holiday', 'is_holiday', 'is_after_holiday', 'day_of_week_sin', 'day_of_week_cos']]\n",
    "print(features)\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next we split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (62, 12)\n",
      "Training Labels Shape: (62,)\n",
      "Testing Features Shape: (7, 12)\n",
      "Testing Labels Shape: (7,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After importing and pre-processing data, train random forest regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=200)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Instantiate model\n",
    "arrive_rf = RandomForestRegressor(n_estimators = 200)\n",
    "\n",
    "#Train the model on training data\n",
    "arrive_rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Validate model, make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Features:\n",
      " [[-0.23931566428755865 0.9709418174260518 1.57 0.0 60 33\n",
      "  274.42857142857144 False False False 0.43388373911755823\n",
      "  -0.900968867902419]\n",
      " [0.5680647467311557 0.8229838658936565 2.01 0.0 69 32 268.0 False False\n",
      "  False -0.9749279121818236 -0.2225209339563146]\n",
      " [0.23931566428755774 0.970941817426052 1.57 0.0 65 37 249.125 False\n",
      "  False False -0.7818314824680299 0.6234898018587334]\n",
      " [0.12053668025532226 0.9927088740980541 3.36 0.0 56 49 257.875 False\n",
      "  False False 0.43388373911755823 -0.900968867902419]\n",
      " [0.35460488704253557 0.9350162426854148 1.34 0.0 56 33 256.75 False\n",
      "  False False 0.9749279121818236 -0.22252093395631434]\n",
      " [0.4647231720437685 0.8854560256532099 13.87 0.0 57 34 245.875 False\n",
      "  False False 0.0 1.0]\n",
      " [0.12053668025532226 0.9927088740980541 2.46 0.09 61 49 254.625 False\n",
      "  False False 0.9749279121818236 -0.22252093395631434]] \n",
      "\n",
      "Predictions:\n",
      " [279.79  247.57  238.59  254.36  253.4   270.015 257.985] \n",
      "\n",
      "Test Data:\n",
      " [280 233 226 266 277 291 282] \n",
      "\n",
      "Absolute error table:\n",
      " [ 0. 15. 13. 12. 24. 21. 24.] \n",
      "\n",
      "Mean absolute error: 15.37 arrivals.\n"
     ]
    }
   ],
   "source": [
    "# Validate model\n",
    "predictions = arrive_rf.predict(test_features)\n",
    "print('Test Features:\\n', test_features, '\\n')\n",
    "print('Predictions:\\n', predictions, '\\n')\n",
    "print('Test Data:\\n', test_labels, '\\n')\n",
    "\n",
    "# Calculate mean absolute error\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Absolute error table:\\n', errors.round(), '\\n')\n",
    "print('Mean absolute error:', round(np.mean(errors), 2), 'arrivals.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use mean absolute error to know if our model is effective\n",
    "\n",
    "See what variables our model is actually using to predict our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: day_of_week_sin      Importance: 0.36\n",
      "Variable: running_7d_avg       Importance: 0.18\n",
      "Variable: TMAX                 Importance: 0.12\n",
      "Variable: week_of_year_cos     Importance: 0.08\n",
      "Variable: TMIN                 Importance: 0.08\n",
      "Variable: week_of_year_sin     Importance: 0.06\n",
      "Variable: AWND                 Importance: 0.04\n",
      "Variable: is_before_holiday    Importance: 0.03\n",
      "Variable: day_of_week_cos      Importance: 0.02\n",
      "Variable: PRCP                 Importance: 0.01\n",
      "Variable: is_after_holiday     Importance: 0.01\n",
      "Variable: is_holiday           Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(arrive_rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use info above to remove noise, retrain model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
