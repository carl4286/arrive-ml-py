{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ML algorithms\n",
    "    Dimensionality reduction- eliminate reduntant variables, use as pre-processing before training regression algorithm\n",
    "    Random forest regression- use to actulally predict daily volumes\n",
    "    \n",
    "Deep Learning Models\n",
    "    Neural nets- similar application to random forest regression, but more computationally intensive, needs a lot more data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Import pre-generated CSV file with several colums\n",
    "    date (string)\n",
    "    arrive_num (int)\n",
    "    acuity_1 (int)\n",
    "    acuity_2 (int)\n",
    "    acuity_3 (int)\n",
    "    acuity_4 (int)\n",
    "    acuity_5 (int)\n",
    "    AWIND (int, average wind speed)\n",
    "    PRCP (int, inches precipitation)\n",
    "    TMAX (int, max temp)\n",
    "    TMIN (int, min temp)\n",
    "    \n",
    "Include or extrapolate the following\n",
    "    day_of_week (int or use string and hot-encode)\n",
    "    week_of_year (int)\n",
    "    running_7d_avg (int)\n",
    "    holiday_dist (int)\n",
    "\n",
    "Optional future\n",
    "    temp (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date  arrive_num  acuity_1  acuity_2  acuity_3  acuity_4  acuity_5  \\\n",
      "0 2022-12-01         303         1        37       150       101        11   \n",
      "1 2022-12-02         286         1        33       156        87         8   \n",
      "2 2022-12-03         280         6        44       137        90         1   \n",
      "3 2022-12-04         245         6        45       117        73         0   \n",
      "4 2022-12-05         278         3        31       139       100         0   \n",
      "5 2022-12-06         304         1        34       161        99         4   \n",
      "6 2022-12-07         225         1        27       123        69         4   \n",
      "7 2022-12-08         280         1        41       154        75         5   \n",
      "8 2022-12-09         275         3        34       148        83         5   \n",
      "9 2022-12-10         226         1        30       120        68         4   \n",
      "\n",
      "  day_of_week  week_of_year  AWND  PRCP  TMAX  TMIN  \n",
      "0       thurs            49  4.47   0.0    56    49  \n",
      "1         fri            49  2.01   0.0    58    47  \n",
      "2         sat            49  2.01   0.0    71    41  \n",
      "3         sun            50  2.01   0.0    66    38  \n",
      "4         mon            50  3.58   0.0    60    46  \n",
      "5        tues            50  2.24   0.0    57    38  \n",
      "6         wed            50  3.13   0.0    58    38  \n",
      "7       thurs            50  1.57   0.0    60    33  \n",
      "8         fri            50  1.12   0.0    60    32  \n",
      "9         sat            50  1.12   0.0    61    32  \n"
     ]
    }
   ],
   "source": [
    "# Import data\n",
    "import pandas as pd\n",
    "\n",
    "# Import raw data and preview contents\n",
    "raw_arrival_data = pd.read_csv(\"data/ruhs_arrivals_raw_data.csv\", parse_dates=['date'], infer_datetime_format=True)\n",
    "raw_weather_data = pd.read_csv(\"data/moval_weather.csv\", parse_dates=['DATE'], infer_datetime_format=True)\n",
    "\n",
    "# Add weather data, remove redundant date column\n",
    "raw_data = pd.merge(raw_arrival_data, raw_weather_data, left_on=['date'], right_on=['DATE'], how='inner')\n",
    "raw_data = raw_data.drop('DATE', axis = 1)\n",
    "\n",
    "print(raw_data.head(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Below is where to add derived features like running 7 day average volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-01-17T00:00:00.000000000' '2022-02-21T00:00:00.000000000'\n",
      " '2022-05-30T00:00:00.000000000' '2022-07-04T00:00:00.000000000'\n",
      " '2022-09-05T00:00:00.000000000' '2022-10-10T00:00:00.000000000'\n",
      " '2022-11-11T00:00:00.000000000' '2022-11-24T00:00:00.000000000'\n",
      " '2022-12-26T00:00:00.000000000' '2023-01-02T00:00:00.000000000'\n",
      " '2023-01-16T00:00:00.000000000']\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "<class 'numpy.float64'>\n",
      "         date  arrive_num  acuity_1  acuity_2  acuity_3  acuity_4  acuity_5  \\\n",
      "0  2022-12-01         303         1        37       150       101        11   \n",
      "1  2022-12-02         286         1        33       156        87         8   \n",
      "2  2022-12-03         280         6        44       137        90         1   \n",
      "3  2022-12-04         245         6        45       117        73         0   \n",
      "4  2022-12-05         278         3        31       139       100         0   \n",
      "5  2022-12-06         304         1        34       161        99         4   \n",
      "6  2022-12-07         225         1        27       123        69         4   \n",
      "7  2022-12-08         280         1        41       154        75         5   \n",
      "8  2022-12-09         275         3        34       148        83         5   \n",
      "9  2022-12-10         226         1        30       120        68         4   \n",
      "10 2022-12-11         214         2        28       127        56         0   \n",
      "11 2022-12-12         238         0        35       134        68         1   \n",
      "12 2022-12-13         261         1        23       148        83         5   \n",
      "13 2022-12-14         245         0        35       149        53         3   \n",
      "14 2022-12-15         278         4        48       150        67         8   \n",
      "15 2022-12-16         256         0        35       160        59         1   \n",
      "16 2022-12-17         250         4        45       136        60         4   \n",
      "17 2022-12-18         232         1        38       134        52         4   \n",
      "18 2022-12-19         244         1        44       114        78         6   \n",
      "19 2022-12-20         256         3        41       145        64         0   \n",
      "20 2022-12-21         250         0        37       135        73         5   \n",
      "21 2022-12-22         271         1        27       153        78         8   \n",
      "22 2022-12-23         243         3        40       142        44         6   \n",
      "23 2022-12-24         181         0        20       100        55         5   \n",
      "24 2022-12-25         261         3        44       120        84         3   \n",
      "25 2022-12-26         317         1        44       160       102         9   \n",
      "\n",
      "   day_of_week  week_of_year  AWND  PRCP  TMAX  TMIN  running_7d_avg  \\\n",
      "0        thurs            49  4.47  0.00    56    49      303.000000   \n",
      "1          fri            49  2.01  0.00    58    47      303.000000   \n",
      "2          sat            49  2.01  0.00    71    41      294.500000   \n",
      "3          sun            50  2.01  0.00    66    38      289.666667   \n",
      "4          mon            50  3.58  0.00    60    46      278.500000   \n",
      "5         tues            50  2.24  0.00    57    38      278.400000   \n",
      "6          wed            50  3.13  0.00    58    38      282.666667   \n",
      "7        thurs            50  1.57  0.00    60    33      274.428571   \n",
      "8          fri            50  1.12  0.00    60    32      275.125000   \n",
      "9          sat            50  1.12  0.00    61    32      271.625000   \n",
      "10         sun            51  9.17  0.21    54    37      264.125000   \n",
      "11         mon            51  2.24  0.07    47    37      255.875000   \n",
      "12        tues            51  1.12  0.00    54    35      255.000000   \n",
      "13         wed            51  0.89  0.00    58    31      252.875000   \n",
      "14       thurs            51  2.01  0.00    63    33      245.500000   \n",
      "15         fri            51  8.50  0.00    64    44      252.125000   \n",
      "16         sat            51  7.38  0.00    62    41      249.125000   \n",
      "17         sun            52  0.89  0.00    62    32      246.000000   \n",
      "18         mon            52  1.12  0.00    64    28      246.750000   \n",
      "19        tues            52  0.89  0.00    66    33      250.500000   \n",
      "20         wed            52  1.57  0.00    72    32      252.750000   \n",
      "21       thurs            52  0.89  0.00    70    35      251.375000   \n",
      "22         fri            52  1.12  0.00    70    36      254.625000   \n",
      "23         sat            52  1.57  0.00    78    37      250.250000   \n",
      "24         sun            53  3.36  0.00    82    40      240.875000   \n",
      "25         mon            53  1.34  0.00    79    40      242.250000   \n",
      "\n",
      "    is_before_holiday  is_holiday  is_after_holiday  \n",
      "0               False       False             False  \n",
      "1               False       False             False  \n",
      "2               False       False             False  \n",
      "3               False       False             False  \n",
      "4               False       False             False  \n",
      "5               False       False             False  \n",
      "6               False       False             False  \n",
      "7               False       False             False  \n",
      "8               False       False             False  \n",
      "9               False       False             False  \n",
      "10              False       False             False  \n",
      "11              False       False             False  \n",
      "12              False       False             False  \n",
      "13              False       False             False  \n",
      "14              False       False             False  \n",
      "15              False       False             False  \n",
      "16              False       False             False  \n",
      "17              False       False             False  \n",
      "18              False       False             False  \n",
      "19              False       False             False  \n",
      "20              False       False             False  \n",
      "21              False       False             False  \n",
      "22              False       False             False  \n",
      "23               True       False             False  \n",
      "24              False        True             False  \n",
      "25              False       False              True  \n"
     ]
    }
   ],
   "source": [
    "#import python-dateutil as dateutil\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# TODO: One-hot encode the day of week\n",
    "#raw_data = pd.get_dummies(raw_data)\n",
    "\n",
    "# Calculate running 7-day average\n",
    "arrive_nums = raw_data['arrive_num']\n",
    "running_7d_avg = []\n",
    "for i, arrivals in enumerate(arrive_nums):\n",
    "    prev_index = i-8\n",
    "    start_range = prev_index if prev_index >= 0 else 0\n",
    "    prev_7_days = arrive_nums[start_range : i]\n",
    "    if prev_7_days.empty : prev_7_days = [arrivals]\n",
    "    running_7d_avg.append(np.mean(prev_7_days))\n",
    "raw_data['running_7d_avg'] = running_7d_avg\n",
    "    \n",
    "# TODO: add distance from holiday\n",
    "holidays = np.array(USFederalHolidayCalendar().holidays(start='2022-01-02', end=pd.to_datetime(\"today\")))\n",
    "print(holidays)\n",
    "avail_dates = raw_data['date']\n",
    "is_before_holiday = []\n",
    "is_holiday = []\n",
    "is_after_holiday = []\n",
    "for date in avail_dates:\n",
    "    delta_from_holidays = np.datetime64(date) - holidays\n",
    "    days_from_holiday = [(x / np.timedelta64(1, 'D')) + 1 for x in delta_from_holidays]\n",
    "    smallest_delta = min(days_from_holiday, key=abs)\n",
    "    is_before_holiday.append(np.isclose(smallest_delta, -1.0))\n",
    "    is_holiday.append(np.isclose(smallest_delta, 0.0))\n",
    "    is_after_holiday.append(np.isclose(smallest_delta, 1.0))\n",
    "raw_data['is_before_holiday'] = is_before_holiday\n",
    "raw_data['is_holiday'] = is_holiday\n",
    "raw_data['is_after_holiday'] = is_after_holiday\n",
    "\n",
    "print(raw_data.head(26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date column, as we only need this to extrapolate other features, not to train model\n",
    "if not raw_data['date'].empty : raw_data = raw_data.drop('date', axis = 1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Labels\n",
    "    arrive_num\n",
    "    acuity_1\n",
    "    acuity_2\n",
    "    acuity_3\n",
    "    acuity_4\n",
    "    acuity_5\n",
    "Features\n",
    "    day_of_week\n",
    "    week_of_year\n",
    "    running_7d_avg\n",
    "    holiday_dist\n",
    "    AWND\n",
    "    PRCP\n",
    "    TMAX\n",
    "    TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     303\n",
      "1     286\n",
      "2     280\n",
      "3     245\n",
      "4     278\n",
      "     ... \n",
      "64    270\n",
      "65    233\n",
      "66    247\n",
      "67    292\n",
      "68    296\n",
      "Name: arrive_num, Length: 69, dtype: int64\n",
      "    day_of_week  week_of_year   AWND  PRCP  TMAX  TMIN  running_7d_avg\n",
      "0             5            49   4.47   0.0    56    49      303.000000\n",
      "1             6            49   2.01   0.0    58    47      303.000000\n",
      "2             7            49   2.01   0.0    71    41      294.500000\n",
      "3             1            50   2.01   0.0    66    38      289.666667\n",
      "4             2            50   3.58   0.0    60    46      278.500000\n",
      "..          ...           ...    ...   ...   ...   ...             ...\n",
      "64            6             5   2.01   0.0    67    37      266.750000\n",
      "65            7             5   2.01   0.0    69    32      268.000000\n",
      "66            1             6   3.58   0.0    61    37      264.125000\n",
      "67            2             6  12.08   0.0    62    39      266.000000\n",
      "68            3             6   3.13   0.0    66    34      273.500000\n",
      "\n",
      "[69 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Define features and labels\n",
    "\n",
    "# Labels: values we want to predict\n",
    "labels = raw_data['arrive_num'] # Un-comment to predict total daily arrivals only\n",
    "#labels = raw_data[['arrive_num', 'acuity_1', 'acuity_2', 'acuity_3', 'acuity_4', 'acuity_5']] # Un-comment to predict arrivals and acuities\n",
    "print(labels)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Features: data that will train model, corresponds to input data when predicting labels\n",
    "features = raw_data[['day_of_week', 'week_of_year', 'AWND', 'PRCP', 'TMAX', 'TMIN', 'running_7d_avg']]\n",
    "print(features)\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next we split data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (62, 7)\n",
      "Training Labels Shape: (62,)\n",
      "Testing Features Shape: (7, 7)\n",
      "Testing Labels Shape: (7,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After importing and pre-processing data, train random forest regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train random forest regression model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "#Instantiate model\n",
    "arrive_rf = RandomForestRegressor(n_estimators = 100)\n",
    "\n",
    "#Train the model on training data\n",
    "arrive_rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Validate model, make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Features:\n",
      " [[  7.  52.   2.   0.  78.  37. 250.]\n",
      " [  4.   2.   2.   0.  57.  39. 253.]\n",
      " [  2.  51.   2.   0.  47.  37. 256.]\n",
      " [  6.  53.   1.   0.  56.  51. 260.]\n",
      " [  5.  49.   4.   0.  56.  49. 303.]\n",
      " [  7.  49.   2.   0.  71.  41. 294.]\n",
      " [  5.  50.   2.   0.  60.  33. 274.]] \n",
      "\n",
      "Predictions:\n",
      " [241.19 261.26 273.3  264.45 261.14 240.77 278.03] \n",
      "\n",
      "Test Data:\n",
      " [181 265 238 255 303 280 280] \n",
      "\n",
      "Absolute error table:\n",
      " [60.  4. 35.  9. 42. 39.  2.] \n",
      "\n",
      "Mean absolute error: 27.39 arrivals.\n"
     ]
    }
   ],
   "source": [
    "# Validate model\n",
    "predictions = arrive_rf.predict(test_features)\n",
    "print('Test Features:\\n', test_features.round(), '\\n')\n",
    "print('Predictions:\\n', predictions, '\\n')\n",
    "print('Test Data:\\n', test_labels, '\\n')\n",
    "\n",
    "# Calculate mean absolute error\n",
    "errors = abs(predictions - test_labels)\n",
    "print('Absolute error table:\\n', errors.round(), '\\n')\n",
    "print('Mean absolute error:', round(np.mean(errors), 2), 'arrivals.')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use mean absolute error to know if our model is effective\n",
    "\n",
    "See what variables our model is actually using to predict our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: day_of_week          Importance: 0.42\n",
      "Variable: running_7d_avg       Importance: 0.22\n",
      "Variable: TMIN                 Importance: 0.1\n",
      "Variable: week_of_year         Importance: 0.09\n",
      "Variable: AWND                 Importance: 0.08\n",
      "Variable: TMAX                 Importance: 0.07\n",
      "Variable: PRCP                 Importance: 0.02\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(arrive_rf.feature_importances_)\n",
    "\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Use info above to remove noise, retrain model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
